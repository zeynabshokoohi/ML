{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 \n",
    "\n",
    "Database: (50_Startups)\n",
    "\n",
    "You are being hired as a Data Scientist client wants\n",
    "to create a model that can predict the profit of\n",
    "the company based on company's location and Rd expense\n",
    "(features : R&D Spend,State(company's location) )\n",
    "Client expects the minimum accuracy of 0.92 of the deployed model\n",
    "\n",
    "Your job is to check the feasibility of the project and create best training \n",
    "and testing splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we here forced to just use 2 columns: R&D and location.\n",
    "\n",
    "''' \n",
    "  but ideally we need to do all these steps to get good result:\n",
    "  - EDA\n",
    "  - Statistical Test\n",
    "  - Feature Engineering\n",
    "  - Then we do cross validation\n",
    "  - \n",
    "\n",
    "'''\n",
    "# if our base algorithms with the base parameters is giving us, we dont go for hyperparameter tuning.\n",
    "# if we dont get result with base algorithms with the base parameters, we will go for hyperparameter tuning.\n",
    "\n",
    "# We go to hyperparameter tuning, when the defalut parameters dont give us a desire output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('50_Startups.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0  165349.20       136897.80        471784.10    New York  192261.83\n",
       "1  162597.70       151377.59        443898.53  California  191792.06\n",
       "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3  144372.41       118671.85        383199.62    New York  182901.99\n",
       "4  142107.34        91391.77        366168.42     Florida  166187.94"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([165349.2, 136897.8, 471784.1, 'New York', 192261.83], dtype=object)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data[0]\n",
    "data.iloc[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   R&D Spend        50 non-null     float64\n",
      " 1   Administration   50 non-null     float64\n",
      " 2   Marketing Spend  50 non-null     float64\n",
      " 3   State            50 non-null     object \n",
      " 4   Profit           50 non-null     float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R&D Spend          0\n",
       "Administration     0\n",
       "Marketing Spend    0\n",
       "State              0\n",
       "Profit             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   R&D Spend        50 non-null     float64\n",
      " 1   Administration   50 non-null     float64\n",
      " 2   Marketing Spend  50 non-null     float64\n",
      " 3   State            50 non-null     object \n",
      " 4   Profit           50 non-null     float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data['R&D Spend'].fillna(round(data['R&D Spend'].mean()), inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['Marketing Spend'].fillna(round(data['Marketing Spend'].mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['State'].fillna(data['State'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = data.iloc[:,:-1].values\n",
    "#label = data.iloc[:,[-1]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finalData = pd.concat([pd.get_dummies(data.State, dtype=int), data.iloc[:,[0,1,2,4]]] , axis = 1)\n",
    "#finalData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Data Handling\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "fState = ohe.fit_transform(np.array(data['State']).reshape(-1,1))\n",
    "#features = np.concatenate([fState, np.array(data.iloc[:, [0,1,2]])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = finalData.iloc[:,:-1].values\n",
    "#label = finalData.iloc[:,[-1]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate([fState, np.array(data.iloc[:, [0]])], axis=1)\n",
    "label = data.iloc[:, [-1]].values\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "modelTest = KNeighborsRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -9.52847973,  -2.42061691,  -7.28965118, -22.85356329,\n",
       "        -0.37428142,  -8.95243978, -33.5713245 ,  -1.3902268 ,\n",
       "        -1.76905992,  -3.65968395])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "scores = cross_val_score(modelTest,\n",
    "                        features,\n",
    "                        label,\n",
    "                        cv = 10)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Score Threshold is :  -9.180932748418233\n",
      "Suggested SL value to commit:  10.180932748418233\n"
     ]
    }
   ],
   "source": [
    "# What is the minimum score threshold for this dataset?\n",
    "\n",
    "print(\"Minimum Score Threshold is : \",scores.mean())\n",
    "print(\"Suggested SL value to commit: \", 1-scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.37428142250826335"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Goal: To identify the best Hyperparamter combinations for KNN w.r.t 50_Startups dataset\n",
    "#      that can give me the score > 0.92"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1 --- Using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nKNeighborsRegressor(               \\nn_neighbors=5,\\t               Positive Integer\\n*,\\nweights=\\'uniform\\',             ‘uniform’, \\'distance\\'\\nalgorithm=\\'auto\\',              ‘auto’, ‘ball_tree’, ‘kd_tree’, ‘brute’\\nleaf_size=30,                  Positive Integer\\np=2,                           1 (Manhattan distance),   2(Elucidean distance)\\nmetric=\\'minkowski\\',            \"“euclidean”, “manhattan”, “chebyshev”, “minkowski”\\n                               “wminkowski”, “seuclidean”, “mahalanobis”\"\\nmetric_params=None,            Dictionary\\nn_jobs=None                    -1, 1 or -2\\n)\\n\\n'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "KNeighborsRegressor(               \n",
    "n_neighbors=5,\t               Positive Integer\n",
    "*,\n",
    "weights='uniform',             ‘uniform’, 'distance'\n",
    "algorithm='auto',              ‘auto’, ‘ball_tree’, ‘kd_tree’, ‘brute’\n",
    "leaf_size=30,                  Positive Integer\n",
    "p=2,                           1 (Manhattan distance),   2(Elucidean distance)\n",
    "metric='minkowski',            \"“euclidean”, “manhattan”, “chebyshev”, “minkowski”\n",
    "                               “wminkowski”, “seuclidean”, “mahalanobis”\"\n",
    "metric_params=None,            Dictionary\n",
    "n_jobs=None                    -1, 1 or -2\n",
    ")\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step1: Design the parameter grid. In Python, you can represent parameter grid in the form of Dictionary\n",
    "\n",
    "weightsParameter = ['uniform','distance']\n",
    "n_neighborsParameter = np.arange(1,31)\n",
    "algorithmParameter = ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "metricParameter = ['euclidean', 'manhattan', 'chebyshev' , 'minkowski', 'seuclidean', 'mahalanobis']\n",
    "\n",
    "\n",
    "paramGrid = dict(n_neighbors = n_neighborsParameter,\n",
    "                weights= weightsParameter,\n",
    "                algorithm = algorithmParameter,\n",
    "                metric=metricParameter)\n",
    "\n",
    "# Step2: Initialize the algo\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "modelGridSearch = KNeighborsRegressor()\n",
    "\n",
    "#Step3: Search the best parameter for your data\n",
    "\n",
    "#GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(modelGridSearch,\n",
    "                   param_grid=paramGrid,\n",
    "                   cv = 10) #Same as cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=KNeighborsRegressor(),\n",
       "             param_grid={&#x27;algorithm&#x27;: [&#x27;auto&#x27;, &#x27;ball_tree&#x27;, &#x27;kd_tree&#x27;, &#x27;brute&#x27;],\n",
       "                         &#x27;metric&#x27;: [&#x27;euclidean&#x27;, &#x27;manhattan&#x27;, &#x27;chebyshev&#x27;,\n",
       "                                    &#x27;minkowski&#x27;, &#x27;seuclidean&#x27;, &#x27;mahalanobis&#x27;],\n",
       "                         &#x27;n_neighbors&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]),\n",
       "                         &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=KNeighborsRegressor(),\n",
       "             param_grid={&#x27;algorithm&#x27;: [&#x27;auto&#x27;, &#x27;ball_tree&#x27;, &#x27;kd_tree&#x27;, &#x27;brute&#x27;],\n",
       "                         &#x27;metric&#x27;: [&#x27;euclidean&#x27;, &#x27;manhattan&#x27;, &#x27;chebyshev&#x27;,\n",
       "                                    &#x27;minkowski&#x27;, &#x27;seuclidean&#x27;, &#x27;mahalanobis&#x27;],\n",
       "                         &#x27;n_neighbors&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]),\n",
       "                         &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=KNeighborsRegressor(),\n",
       "             param_grid={'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
       "                         'metric': ['euclidean', 'manhattan', 'chebyshev',\n",
       "                                    'minkowski', 'seuclidean', 'mahalanobis'],\n",
       "                         'n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]),\n",
       "                         'weights': ['uniform', 'distance']})"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step4: Extract Results\n",
    "\n",
    "grid.fit(features,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.180932748418233"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsRegressor(metric=&#x27;euclidean&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" checked><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor(metric=&#x27;euclidean&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsRegressor(metric='euclidean')"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto',\n",
       " 'metric': 'euclidean',\n",
       " 'n_neighbors': 5,\n",
       " 'weights': 'uniform'}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalModel = KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='euclidean',\n",
    "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
    "                     weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score 0.9698645019723984, Train Score 0.9490707851165177 for Sample Split 1\n",
      "Test Score 0.9463413631002947, Train Score 0.939325042435145 for Sample Split 2\n",
      "Test Score 0.8175128802662227, Train Score 0.9618423677474436 for Sample Split 4\n",
      "Test Score 0.8802723288889419, Train Score 0.9548311766994682 for Sample Split 6\n",
      "Test Score 0.8334705324417688, Train Score 0.9593927337275211 for Sample Split 7\n",
      "Test Score 0.9783274092181723, Train Score 0.945124231648262 for Sample Split 8\n",
      "Test Score 0.9597975025427307, Train Score 0.9549506955543277 for Sample Split 10\n"
     ]
    }
   ],
   "source": [
    "# 3. To extract the best training sample that gives the best score for KNeighborsRegressor\n",
    "\n",
    "# Step1: Initialize the algo\n",
    "#from sklearn.neighbors import KNeighborsRegressor\n",
    "#modelTest = KNeighborsRegressor()\n",
    "\n",
    "# Step2: Initialize K-Fold Cross Validation function\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(n_splits=10, #Use the same CV values that was applied in cross_val_score\n",
    "             shuffle=True,\n",
    "             random_state = 1) # To ensure the data is not randomized at every iteration\n",
    "\n",
    "# 3. initialize for loop to identify which sample gives the best score and which sample is the best \n",
    "#.   training sample\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for train,test in kfold.split(features):\n",
    "    \n",
    "    #Counter will help you track the sample split\n",
    "    counter += 1\n",
    "    \n",
    "    #Extract the training set and testing set\n",
    "    X_train,X_test = features[train],features[test]\n",
    "    y_train,y_test = label[train] , label[test]\n",
    "    \n",
    "    #Fit the model \n",
    "    finalModel.fit(X_train,y_train)\n",
    "\n",
    "    if finalModel.score(X_test,y_test) >= 0.8:\n",
    "       print(\"Test Score {}, Train Score {} for Sample Split {}\".format(finalModel.score(X_test,y_test),finalModel.score(X_train,y_train),counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9597975025427307"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalModel.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the samples\n",
    "# Step1: Initialize the algo\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "modelTest = KNeighborsRegressor()\n",
    "\n",
    "# Step2: Initialize K-Fold Cross Validation function\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(n_splits=10, #Use the same CV values that was applied in cross_val_score\n",
    "             shuffle=True,\n",
    "             random_state = 1) # To ensure the data is not randomized at every iteration\n",
    "\n",
    "# 3. initialize for loop to identify which sample gives the best score and which sample is the best \n",
    "#.   training sample\n",
    "\n",
    "counter = 0\n",
    "for train,test in kfold.split(features):\n",
    "    \n",
    "    #Counter will help you track the sample split\n",
    "    counter += 1\n",
    "    \n",
    "    if counter == 1:\n",
    "        X_train,X_test,y_train,y_test = features[train],features[test],label[train] , label[test]\n",
    "    \n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object _BaseKFold.split at 0x29f00a500>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold.split(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9698645019723984"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "finalModel = KNeighborsRegressor()\n",
    "finalModel.fit(X_train,y_train)\n",
    "finalModel.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "KNeighborsRegressor,\n",
    "LinearRegression,\n",
    "RandomForestRegressor, \n",
    "DecisionTreeRegressor all give negative values.\n",
    "I'm trying svm and gradient boosting, if that doesn't work then boosting\n",
    "'''\n",
    "\n",
    "#result for minimum score from another student. (just have it to compare with mine)\n",
    "\n",
    "#Algorithm: KNeighborsRegressor:  score.mean(): -9.180932748418233 \n",
    "#Algorithm: LinearRegression; score.mean(): -5.36154501542167 \n",
    "#Algorithm: Ridge; score.mean(): -5.321536240939532 \n",
    "#Algorithm: Lasso; score.mean(): -5.359454343797066 \n",
    "#Algorithm: SVR; score.mean(): -71.61028643587005 \n",
    "#Algorithm: DecisionTreeRegressor; score.mean(): -13.275206556089353 \n",
    "#Algorithm: RandomForestRegressor; score.mean(): -11.003588853560279\n",
    "\n",
    "''' \n",
    "tried all the regressors I knew at cv=10 and got horrible results,\n",
    "changed cvt to 5 and went back to the linear regressor and\n",
    "found a favorable set of train/test data and got a final model test score at 0.985,\n",
    "so I guess... if I've done it right,\n",
    "I could say that the noted CL is achievable yet it takes very careful selection of splits with means bad\n",
    "but there are a few good spots on the max side.\n",
    "I say that with caution as the distribution of results is widely divergent.\n",
    "'''\n",
    "\n",
    "''' \n",
    "I'm running the XBGboostingRegressor with a grid search. Taking forever.\n",
    "'''\n",
    "\n",
    "''' \n",
    "#KNeighborsRegressor -13.43588015457872 \n",
    "#LinearRegression -13.43588015457872 \n",
    "#Random Forest Regressor 0.9943311099704247 0.9900294965255345 \n",
    "#Decision Tree Regressor 0.9997560609325686 0.9986157840020002 \n",
    "#XGBoost: (I used Regressor for XGBoost)\n",
    " Test : 0.8990283826136631 Train: 0.8831413505997752 RS: 1 \n",
    " Test : 0.8885681990121184 Train: 0.8873581704751071 RS: 2 \n",
    " Test : 0.9408557499271855 Train: 0.887162877264517 RS: 3 \n",
    " Test : 0.9130436650669594 Train: 0.8982483398878128 RS: 4 \n",
    " Test : 0.9066007611880108 Train: 0.8798352225364479 RS: 8 \n",
    " Test : 0.9135009638877835 Train: 0.8890726702949123 RS: 10 \n",
    " Test : 0.9211583984841318 Train: 0.8877585247195765 RS: 11 \n",
    " Test : 0.9265103822461054 Train: 0.8940650907921229 RS: 12 \n",
    " Test : 0.9246043552813843 Train: 0.8863996889153201 RS: 15 \n",
    " Test : 0.8992791509253291 Train: 0.8964649984406764 RS: 17 \n",
    " Test : 0.9585460293356046 Train: 0.8853890872909793 RS: 18 \n",
    " Test : 0.9238989935437033 Train: 0.8985493208721518 RS: 19 \n",
    " Test : 0.9182179346684616 Train: 0.8918856055807115 RS: 21 \n",
    " Test : 0.9552338091339604 Train: 0.8875759198\n",
    "'''\n",
    "\n",
    "''' \n",
    "markG -- what were the cues that LinearRegression was most promising model? (for me score.mean() was -0.33 for it)\n",
    "\n",
    "answer:had a good max so I figured I'd go after the needle in the haystack so to speak...\n",
    "I'm sure there are similar opportunities with other algorithms...\n",
    "'''\n",
    "\n",
    "'''  \n",
    "if we decrease the CV to 2 or 3, lin regression gets quite good.\n",
    " At CV that low, does this turn the regression model into a de facto classifier?\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "if cross_val_score doesnt give you a good answer, the recommendation is use k-fold, shuffle spread or StratifiedKFold\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
