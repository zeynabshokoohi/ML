{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 50 Startups dataset - K-Neighbors Regressor Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('50_Startups.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   R&D Spend        50 non-null     float64\n",
      " 1   Administration   50 non-null     float64\n",
      " 2   Marketing Spend  50 non-null     float64\n",
      " 3   State            50 non-null     object \n",
      " 4   Profit           50 non-null     float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R&D Spend          0\n",
       "Administration     0\n",
       "Marketing Spend    0\n",
       "State              0\n",
       "Profit             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   R&D Spend        50 non-null     float64\n",
      " 1   Administration   50 non-null     float64\n",
      " 2   Marketing Spend  50 non-null     float64\n",
      " 3   State            50 non-null     object \n",
      " 4   Profit           50 non-null     float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data['R&D Spend'].fillna( round(data['R&D Spend'].mean()) , inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   R&D Spend        50 non-null     float64\n",
      " 1   Administration   50 non-null     float64\n",
      " 2   Marketing Spend  50 non-null     float64\n",
      " 3   State            50 non-null     object \n",
      " 4   Profit           50 non-null     float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data['Marketing Spend'].fillna( round(data['Marketing Spend'].mean()) , inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   R&D Spend        50 non-null     float64\n",
      " 1   Administration   50 non-null     float64\n",
      " 2   Marketing Spend  50 non-null     float64\n",
      " 3   State            50 non-null     object \n",
      " 4   Profit           50 non-null     float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data['State'].fillna( data['State'].mode()[0] , inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0000000e+00 0.0000000e+00 1.0000000e+00 1.6534920e+05 1.3689780e+05\n",
      "  4.7178410e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.6259770e+05 1.5137759e+05\n",
      "  4.4389853e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.5344151e+05 1.0114555e+05\n",
      "  4.0793454e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 1.4437241e+05 1.1867185e+05\n",
      "  3.8319962e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.4210734e+05 9.1391770e+04\n",
      "  3.6616842e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 1.3187690e+05 9.9814710e+04\n",
      "  3.6286136e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.3461546e+05 1.4719887e+05\n",
      "  1.2771682e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.3029813e+05 1.4553006e+05\n",
      "  3.2387668e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 1.2054252e+05 1.4871895e+05\n",
      "  3.1161329e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.2333488e+05 1.0867917e+05\n",
      "  3.0498162e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0191308e+05 1.1059411e+05\n",
      "  2.2916095e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.0067196e+05 9.1790610e+04\n",
      "  2.4974455e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 9.3863750e+04 1.2732038e+05\n",
      "  2.4983944e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 9.1992390e+04 1.3549507e+05\n",
      "  2.5266493e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.1994324e+05 1.5654742e+05\n",
      "  2.5651292e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 1.1452361e+05 1.2261684e+05\n",
      "  2.6177623e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 7.8013110e+04 1.2159755e+05\n",
      "  2.6434606e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 9.4657160e+04 1.4507758e+05\n",
      "  2.8257431e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 9.1749160e+04 1.1417579e+05\n",
      "  2.9491957e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 8.6419700e+04 1.5351411e+05\n",
      "  0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 7.6253860e+04 1.1386730e+05\n",
      "  2.9866447e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 7.8389470e+04 1.5377343e+05\n",
      "  2.9973729e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 7.3994560e+04 1.2278275e+05\n",
      "  3.0331926e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.7532530e+04 1.0575103e+05\n",
      "  3.0476873e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 7.7044010e+04 9.9281340e+04\n",
      "  1.4057481e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 6.4664710e+04 1.3955316e+05\n",
      "  1.3796262e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 7.5328870e+04 1.4413598e+05\n",
      "  1.3405007e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 7.2107600e+04 1.2786455e+05\n",
      "  3.5318381e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.6051520e+04 1.8264556e+05\n",
      "  1.1814820e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 6.5605480e+04 1.5303206e+05\n",
      "  1.0713838e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.1994480e+04 1.1564128e+05\n",
      "  9.1131240e+04]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 6.1136380e+04 1.5270192e+05\n",
      "  8.8218230e+04]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 6.3408860e+04 1.2921961e+05\n",
      "  4.6085250e+04]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.5493950e+04 1.0305749e+05\n",
      "  2.1463481e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 4.6426070e+04 1.5769392e+05\n",
      "  2.1079767e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 4.6014020e+04 8.5047440e+04\n",
      "  2.0551764e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.8663760e+04 1.2705621e+05\n",
      "  2.0112682e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 4.4069950e+04 5.1283140e+04\n",
      "  1.9702942e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 2.0229590e+04 6.5947930e+04\n",
      "  1.8526510e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 3.8558510e+04 8.2982090e+04\n",
      "  1.7499930e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.8754330e+04 1.1854605e+05\n",
      "  1.7279567e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.7892920e+04 8.4710770e+04\n",
      "  1.6447071e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.3640930e+04 9.6189630e+04\n",
      "  1.4800111e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 1.5505730e+04 1.2738230e+05\n",
      "  3.5534170e+04]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.2177740e+04 1.5480614e+05\n",
      "  2.8334720e+04]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 1.0002300e+03 1.2415304e+05\n",
      "  1.9039300e+03]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.3154600e+03 1.1581621e+05\n",
      "  2.9711446e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.3542692e+05\n",
      "  0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 5.4205000e+02 5.1743150e+04\n",
      "  0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.1698380e+05\n",
      "  4.5173060e+04]]\n",
      "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
      "0  165349.20       136897.80        471784.10    New York  192261.83\n",
      "1  162597.70       151377.59        443898.53  California  191792.06\n",
      "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
      "3  144372.41       118671.85        383199.62    New York  182901.99\n",
      "4  142107.34        91391.77        366168.42     Florida  166187.94\n"
     ]
    }
   ],
   "source": [
    "# Categorical Data Handling\n",
    "\n",
    "# Using Sci-kit Package\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "\n",
    "fState = ohe.fit_transform( np.array(data['State']).reshape(-1,1) )\n",
    "\n",
    "\n",
    "features = np.concatenate( [fState , np.array(data.iloc[:,[0,1,2]])] , axis = 1)\n",
    "print(features)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = data.iloc[:,[4]].values.ravel()\n",
    "#print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement K-Neighbors Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score 0.955833249359642, Train Score 0.8455978942730887, RandomSeed 1\n",
      "Test Score 0.9152432725356717, Train Score 0.8450600157501783, RandomSeed 2\n",
      "Test Score 0.9205222077814073, Train Score 0.844809521066878, RandomSeed 3\n",
      "Test Score 0.9503990063815226, Train Score 0.8458668403613925, RandomSeed 9\n",
      "Test Score 0.9350659791404976, Train Score 0.8431596273167298, RandomSeed 11\n",
      "Test Score 0.9080917614915126, Train Score 0.8583950730467481, RandomSeed 16\n",
      "Test Score 0.9026020881073196, Train Score 0.8512130981341051, RandomSeed 21\n",
      "Test Score 0.9712845881274329, Train Score 0.851978128828738, RandomSeed 22\n",
      "Test Score 0.9710647177256582, Train Score 0.8411316909069131, RandomSeed 26\n",
      "Test Score 0.9226471818560702, Train Score 0.8623642100459619, RandomSeed 33\n",
      "Test Score 0.9366615187756205, Train Score 0.8494501786168597, RandomSeed 38\n",
      "Test Score 0.9426072706043019, Train Score 0.8452984950399025, RandomSeed 39\n",
      "Test Score 0.906208322578222, Train Score 0.7990892129965338, RandomSeed 48\n",
      "Test Score 0.9724730782974068, Train Score 0.8672692388127128, RandomSeed 49\n",
      "Test Score 0.9087813262539721, Train Score 0.8262649754978078, RandomSeed 51\n",
      "Test Score 0.9046495352674062, Train Score 0.859695853703925, RandomSeed 57\n",
      "Test Score 0.9932009504666949, Train Score 0.8552259199416467, RandomSeed 60\n",
      "Test Score 0.969479751030397, Train Score 0.8540656062326556, RandomSeed 62\n",
      "Test Score 0.9331824264004474, Train Score 0.8419662329777052, RandomSeed 64\n",
      "Test Score 0.9144941689007672, Train Score 0.8063037108970108, RandomSeed 66\n",
      "Test Score 0.9778518155971471, Train Score 0.8546035045336076, RandomSeed 68\n",
      "Test Score 0.9707273017213194, Train Score 0.8572521047054487, RandomSeed 71\n",
      "Test Score 0.9059302870513729, Train Score 0.8491477623381531, RandomSeed 80\n",
      "Test Score 0.9105294927971632, Train Score 0.8535536062647169, RandomSeed 82\n",
      "Test Score 0.9131971479787983, Train Score 0.8265419084503073, RandomSeed 85\n",
      "Test Score 0.9594603109732808, Train Score 0.8541472047365996, RandomSeed 89\n",
      "Test Score 0.9542300655751323, Train Score 0.8571864291452517, RandomSeed 96\n",
      "Test Score 0.9003060366032816, Train Score 0.8504397848305664, RandomSeed 98\n",
      "Test Score 0.9291882346566216, Train Score 0.8028668053264599, RandomSeed 103\n",
      "Test Score 0.9614724498828737, Train Score 0.8562541892681484, RandomSeed 105\n",
      "Test Score 0.9020480504792446, Train Score 0.8471670374622758, RandomSeed 116\n",
      "Test Score 0.9289427508602849, Train Score 0.8321016800208932, RandomSeed 119\n",
      "Test Score 0.9176975018040977, Train Score 0.8407974790157565, RandomSeed 120\n",
      "Test Score 0.9545180956283044, Train Score 0.8505455070495206, RandomSeed 126\n",
      "Test Score 0.9768710801885401, Train Score 0.8481845067453913, RandomSeed 128\n",
      "Test Score 0.9239216016316251, Train Score 0.8380722802700601, RandomSeed 130\n",
      "Test Score 0.9283358215665649, Train Score 0.848799258755927, RandomSeed 151\n",
      "Test Score 0.9249610648073635, Train Score 0.8420719303501762, RandomSeed 152\n",
      "Test Score 0.9426139345746104, Train Score 0.8486719483444519, RandomSeed 153\n",
      "Test Score 0.9279549544250042, Train Score 0.8405696969130012, RandomSeed 155\n",
      "Test Score 0.9441596139312958, Train Score 0.8458839365623537, RandomSeed 159\n",
      "Test Score 0.9408574006202904, Train Score 0.8393056314570373, RandomSeed 162\n",
      "Test Score 0.901434785701847, Train Score 0.8504841306644777, RandomSeed 169\n",
      "Test Score 0.915031974313808, Train Score 0.8395283438889741, RandomSeed 180\n",
      "Test Score 0.9519787917160537, Train Score 0.8576285644083937, RandomSeed 182\n",
      "Test Score 0.9697041860567145, Train Score 0.8461268517178716, RandomSeed 184\n",
      "Test Score 0.9690549375226934, Train Score 0.8396685613052074, RandomSeed 190\n",
      "Test Score 0.9655995493598714, Train Score 0.8399832117775368, RandomSeed 195\n",
      "Test Score 0.9286212364831774, Train Score 0.8523286876686017, RandomSeed 196\n",
      "Test Score 0.9597638212431147, Train Score 0.8484290326814146, RandomSeed 197\n",
      "Test Score 0.9578876360161112, Train Score 0.8508901219210582, RandomSeed 199\n",
      "Test Score 0.9022088685611743, Train Score 0.8582355711719237, RandomSeed 203\n",
      "Test Score 0.9584655111831271, Train Score 0.8544413899542298, RandomSeed 204\n",
      "Test Score 0.9597909597137304, Train Score 0.8416456170652297, RandomSeed 209\n",
      "Test Score 0.960929763636519, Train Score 0.8530497998360496, RandomSeed 210\n",
      "Test Score 0.942883267064758, Train Score 0.8477901330299726, RandomSeed 211\n",
      "Test Score 0.9851930694467846, Train Score 0.851599471823856, RandomSeed 212\n",
      "Test Score 0.9209450993535757, Train Score 0.8356641733344531, RandomSeed 213\n",
      "Test Score 0.9257594472046518, Train Score 0.8560156150397591, RandomSeed 214\n",
      "Test Score 0.9401331837247755, Train Score 0.8422969611553122, RandomSeed 219\n",
      "Test Score 0.9216283106752112, Train Score 0.8552431388555406, RandomSeed 221\n",
      "Test Score 0.9149987833383284, Train Score 0.8514272245426373, RandomSeed 223\n",
      "Test Score 0.9218017894284201, Train Score 0.8518888551628214, RandomSeed 238\n",
      "Test Score 0.9422410552819229, Train Score 0.8324175948792604, RandomSeed 239\n",
      "Test Score 0.9345978080762504, Train Score 0.8512936750093265, RandomSeed 241\n",
      "Test Score 0.9543269414002141, Train Score 0.8500181117060615, RandomSeed 242\n",
      "Test Score 0.9123254138016822, Train Score 0.8437669149228799, RandomSeed 243\n",
      "Test Score 0.948565037090668, Train Score 0.8221638294423808, RandomSeed 246\n",
      "Test Score 0.9621895151270161, Train Score 0.8496897208363221, RandomSeed 248\n",
      "Test Score 0.9233913161432044, Train Score 0.843865267944686, RandomSeed 252\n",
      "Test Score 0.9163801436981738, Train Score 0.8492154447440006, RandomSeed 255\n",
      "Test Score 0.978120958643715, Train Score 0.8583767193668966, RandomSeed 257\n",
      "Test Score 0.9266914267989628, Train Score 0.855347677451409, RandomSeed 262\n",
      "Test Score 0.951638914241024, Train Score 0.8546774049974893, RandomSeed 265\n",
      "Test Score 0.9495747270760263, Train Score 0.8420888935427856, RandomSeed 268\n",
      "Test Score 0.9580994226310933, Train Score 0.8499209502597019, RandomSeed 270\n",
      "Test Score 0.9443644279180995, Train Score 0.8477568706468821, RandomSeed 284\n",
      "Test Score 0.9078133172196441, Train Score 0.8528539408024111, RandomSeed 285\n",
      "Test Score 0.9307963771993601, Train Score 0.8417682614897486, RandomSeed 297\n",
      "Test Score 0.9121328791140162, Train Score 0.814404528138581, RandomSeed 301\n",
      "Test Score 0.9012173355087476, Train Score 0.8309494347324247, RandomSeed 306\n",
      "Test Score 0.9527337576120899, Train Score 0.82832712075044, RandomSeed 309\n",
      "Test Score 0.9409789859690627, Train Score 0.857955814803758, RandomSeed 310\n",
      "Test Score 0.9408623390065218, Train Score 0.8616200899294353, RandomSeed 315\n",
      "Test Score 0.9625055518312685, Train Score 0.8595013892598166, RandomSeed 321\n",
      "Test Score 0.9341150336671207, Train Score 0.854619441503079, RandomSeed 322\n",
      "Test Score 0.9232207831574166, Train Score 0.8613434520330427, RandomSeed 325\n",
      "Test Score 0.9281237511191953, Train Score 0.8503310866233484, RandomSeed 334\n",
      "Test Score 0.9423692626830608, Train Score 0.8361805009228386, RandomSeed 336\n",
      "Test Score 0.9587861574140011, Train Score 0.8563714155328244, RandomSeed 338\n",
      "Test Score 0.9110316717900817, Train Score 0.8441012627656826, RandomSeed 341\n",
      "Test Score 0.9352005599076799, Train Score 0.8366805998674893, RandomSeed 342\n",
      "Test Score 0.9450162582381284, Train Score 0.8527610393078248, RandomSeed 344\n",
      "Test Score 0.965307858285594, Train Score 0.8446751013205502, RandomSeed 348\n",
      "Test Score 0.9335158986049248, Train Score 0.7991192870761129, RandomSeed 349\n",
      "Test Score 0.952536002637719, Train Score 0.8467472444854741, RandomSeed 361\n",
      "Test Score 0.9508644620247092, Train Score 0.841409839446547, RandomSeed 363\n",
      "Test Score 0.9298710302131947, Train Score 0.8296504605733958, RandomSeed 368\n",
      "Test Score 0.9364240993857866, Train Score 0.8519585172419436, RandomSeed 369\n",
      "Test Score 0.9784015815673134, Train Score 0.8334409572366098, RandomSeed 370\n",
      "Test Score 0.9408153429607445, Train Score 0.8595508128713122, RandomSeed 374\n",
      "Test Score 0.9577463411138852, Train Score 0.8511890159259186, RandomSeed 378\n",
      "Test Score 0.9162675126551922, Train Score 0.8581956498698036, RandomSeed 379\n",
      "Test Score 0.912703149319945, Train Score 0.8565048248025084, RandomSeed 385\n",
      "Test Score 0.9516566358045044, Train Score 0.8345260216593646, RandomSeed 386\n",
      "Test Score 0.9122400921340377, Train Score 0.8602614087635294, RandomSeed 387\n",
      "Test Score 0.9699231530457865, Train Score 0.8519816085433206, RandomSeed 388\n",
      "Test Score 0.905080569520931, Train Score 0.8503233384676903, RandomSeed 394\n",
      "Test Score 0.9543462881998239, Train Score 0.8423041715663733, RandomSeed 395\n",
      "Test Score 0.9041142359480456, Train Score 0.8370113261733865, RandomSeed 396\n",
      "Test Score 0.9536657346874645, Train Score 0.8344025742554226, RandomSeed 400\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SL = 0.1\n",
    "CL = 1 - SL\n",
    "for i in range(1,401):\n",
    "    X_train,X_test,y_train,y_test = train_test_split(features,label,test_size=0.1,random_state=i)\n",
    "    model = KNeighborsRegressor(n_neighbors=5)\n",
    "    model.fit(X_train,y_train)\n",
    "    train_score = model.score(X_train,y_train)\n",
    "    test_score = model.score(X_test,y_test)\n",
    "    \n",
    "    if test_score > train_score and test_score > CL:\n",
    "        print(\"Test Score {}, Train Score {}, RandomSeed {}\".format(test_score,train_score,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.8552259199416467\n",
      "Test score: 0.9932009504666949\n"
     ]
    }
   ],
   "source": [
    "#Final Model\n",
    "X_train,X_test,y_train,y_test = train_test_split(features,label,test_size=0.1,random_state=60)\n",
    "final_model = KNeighborsRegressor(n_neighbors=5)\n",
    "final_model.fit(X_train,y_train)\n",
    "print(\"Train score:\", final_model.score(X_train,y_train))\n",
    "print(\"Test score:\", final_model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Bagging Regressor with LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(base_estimator=LinearRegression(), n_estimators=100)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear Regression\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "algorithm = LinearRegression()\n",
    "\n",
    "model = BaggingRegressor(n_estimators=100, #No of weak learners\n",
    "                         base_estimator=algorithm) #The algo to be used for learning\n",
    "\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9502959082946706\n",
      "0.9489715900713226\n"
     ]
    }
   ],
   "source": [
    "print(model.score(X_train,y_train))\n",
    "print(model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Bagging Regressor with KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(base_estimator=KNeighborsRegressor(), n_estimators=100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K-Neighbors Regressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "algorithm = KNeighborsRegressor()\n",
    "\n",
    "model = BaggingRegressor(n_estimators=100, #No of weak learners\n",
    "                         base_estimator=algorithm) #The algo to be used for learning\n",
    "\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.842463785895132\n",
      "0.9731761304017041\n"
     ]
    }
   ],
   "source": [
    "print(model.score(X_train,y_train))\n",
    "print(model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.966298754312304 , Test: 0.9842310223890651 , Seed: 126\n",
      "Train: 0.9656550439706006 , Test: 0.96595191432676 , Seed: 181\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "max_depth = 3\n",
    "for i in range(1,401):\n",
    "    X_train,X_test,y_train,y_test = train_test_split(features,label,test_size=0.2,random_state=i)\n",
    "    model_tree = DecisionTreeRegressor(max_depth=max_depth)\n",
    "    model_tree.fit(X_train, y_train)\n",
    "    score_train = model_tree.score(X_train,y_train)\n",
    "    score_test = model_tree.score(X_test,y_test)\n",
    "    if score_test > score_train and score_test > 0.95:\n",
    "        print(\"Train:\", score_train, \", Test:\", score_test, \", Seed:\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_seed = 126\n",
    "X_train,X_test,y_train,y_test = train_test_split(features,label,test_size=0.2,random_state=best_seed)\n",
    "final_model_tree = DecisionTreeRegressor(max_depth=max_depth)\n",
    "final_model_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.966298754312304 , Test: 0.9842310223890651 , Seed: 126\n"
     ]
    }
   ],
   "source": [
    "score_train = final_model_tree.score(X_train,y_train)\n",
    "score_test = final_model_tree.score(X_test,y_test)\n",
    "print(\"Train:\", score_train, \", Test:\", score_test, \", Seed:\", best_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "features = sc.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=6)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "principalComponents = PCA(n_components=6) # 6 features in 50 startups dataset after OHE\n",
    "principalComponents.fit(features,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.26596913e-01, 2.51852089e-01, 2.16730846e-01, 1.68048197e-01,\n",
       "       3.67719551e-02, 2.09922995e-32])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "principalComponents.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance ratios are all low. Use n_components=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=1)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "principalComponentsFinal = PCA(n_components=1) #Here n_components = n_features\n",
    "principalComponentsFinal.fit(features,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.32659691])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "principalComponentsFinal.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalFeatures = principalComponentsFinal.transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsRegressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score 0.9337211099023445, Train Score 0.7065275688397826, RandomSeed 17\n",
      "Test Score 0.9005106670057083, Train Score 0.7036866689631882, RandomSeed 60\n",
      "Test Score 0.9311720105842937, Train Score 0.6746590804109218, RandomSeed 306\n",
      "Test Score 0.9483313736316629, Train Score 0.712237335451444, RandomSeed 325\n",
      "Test Score 0.9243949173640865, Train Score 0.7025830292083617, RandomSeed 328\n",
      "Test Score 0.9234323863128409, Train Score 0.6701512137225252, RandomSeed 378\n",
      "Test Score 0.9317378379528075, Train Score 0.6912087249252477, RandomSeed 525\n",
      "Test Score 0.9029943478247453, Train Score 0.7062550934085838, RandomSeed 529\n",
      "Test Score 0.9524718142323688, Train Score 0.710419298738937, RandomSeed 542\n",
      "Test Score 0.9149938562724854, Train Score 0.6854207630567628, RandomSeed 618\n",
      "Test Score 0.9308653686349264, Train Score 0.6844836408432617, RandomSeed 623\n",
      "Test Score 0.9461468231485978, Train Score 0.682818083844491, RandomSeed 687\n",
      "Test Score 0.9628465728204758, Train Score 0.7133061907637538, RandomSeed 806\n",
      "Test Score 0.9631427041464949, Train Score 0.7009118714720939, RandomSeed 912\n",
      "Test Score 0.9094097745201417, Train Score 0.70423291749132, RandomSeed 980\n",
      "Test Score 0.9246731788574617, Train Score 0.6609891940016628, RandomSeed 1078\n",
      "Test Score 0.9344518020507637, Train Score 0.7208381570908837, RandomSeed 1126\n",
      "Test Score 0.904240219680941, Train Score 0.6652335690268918, RandomSeed 1183\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "for i in range(1,1201):\n",
    "    X_train,X_test,y_train,y_test = train_test_split(finalFeatures,label,test_size=0.1,random_state=i)\n",
    "    knr = KNeighborsRegressor(n_neighbors=7)\n",
    "    #model = BaggingRegressor(n_estimators=5, #No of weak learners\n",
    "                         #base_estimator=knr) #The algo to be used for learning\n",
    "    knr.fit(X_train,y_train)\n",
    "    train_score = knr.score(X_train,y_train)\n",
    "    test_score = knr.score(X_test,y_test)\n",
    "    \n",
    "    if test_score > train_score and test_score > CL:\n",
    "        print(\"Test Score {}, Train Score {}, RandomSeed {}\".format(test_score,train_score,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.8573144168783773 , Test: 0.8776734871682511 , Seed: 108\n",
      "Train: 0.8866096669764724 , Test: 0.9042648548547481 , Seed: 178\n",
      "Train: 0.8667833468838886 , Test: 0.8860698677067947 , Seed: 180\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "max_depth = 5\n",
    "for i in range(1,401):\n",
    "    X_train,X_test,y_train,y_test = train_test_split(finalFeatures,label,test_size=0.15,random_state=i)\n",
    "    model_tree = DecisionTreeRegressor(max_depth=max_depth)\n",
    "    model_tree.fit(X_train, y_train)\n",
    "    score_train = model_tree.score(X_train,y_train)\n",
    "    score_test = model_tree.score(X_test,y_test)\n",
    "    if score_test > score_train and score_test > 0.75:\n",
    "        print(\"Train:\", score_train, \", Test:\", score_test, \", Seed:\", i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBRegressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "for i in range(1,101):\n",
    "    X_train,X_test,y_train,y_test = train_test_split(finalFeatures,\n",
    "                                                    label,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=i)\n",
    "    \n",
    "    model = XGBRegressor(learning_rate=0.001)\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    train_score = model.score(X_train,y_train)\n",
    "    test_score = model.score(X_test,y_test)\n",
    "    \n",
    "    if test_score > train_score and test_score > 0.95:\n",
    "        print(\"Test : {} Train: {} RS: {}\".format(test_score,train_score,i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Despite the low training score, KNeighborsRegressor yielded the best results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seed = 328\n",
    "best_n_neighbors = 10\n",
    "X_train,X_test,y_train,y_test = train_test_split(finalFeatures,label,test_size=0.1,random_state=best_seed)\n",
    "knr = KNeighborsRegressor(n_neighbors=best_n_neighbors)\n",
    "knr.fit(X_train,y_train)\n",
    "train_score = knr.score(X_train,y_train)\n",
    "test_score = knr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.9544029307223478 Train: 0.684829857698274 RS: 328\n"
     ]
    }
   ],
   "source": [
    "print(\"Test : {} Train: {} RS: {}\".format(test_score,train_score,best_seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 0   R&D Spend        50 non-null     float64\n",
    " 1   Administration   50 non-null     float64\n",
    " 2   Marketing Spend  50 non-null     float64\n",
    " 3   State            50 non-null     object \n",
    " 4   Profit           50 non-null     float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter R&D Spending:  50000\n",
      "Enter Administration Spending:  50000\n",
      "Enter Marketing Spending:  50000\n",
      "Enter State:  New York\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[163574.9]\n"
     ]
    }
   ],
   "source": [
    "## Deployment\n",
    "\n",
    "rndSpend = float(input(\"Enter R&D Spending: \"))\n",
    "adminSpend =float(input(\"Enter Administration Spending: \"))\n",
    "marketSpend = float(input(\"Enter Marketing Spending: \"))\n",
    "state = input(\"Enter State: \")\n",
    "if state == \"New York\":\n",
    "    fState = [0,0,1]\n",
    "elif state == \"Florida\":\n",
    "    fState = [0,1,0]\n",
    "else:\n",
    "    fState = [1,0,0]\n",
    "\n",
    "#FeatureSet\n",
    "featureSet = np.concatenate( [[fState] , np.array([[rndSpend,adminSpend,marketSpend]])], axis = 1)\n",
    "\n",
    "#Standardization\n",
    "featureStandardizedSet = sc.transform(featureSet)\n",
    "\n",
    "#transform features using PCA\n",
    "principalCFeatures = principalComponentsFinal.transform(featureStandardizedSet)\n",
    "\n",
    "#Predict\n",
    "print(knr.predict(principalCFeatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pickle Code\n",
    "import pickle\n",
    "#Deploy StandardScaler Object\n",
    "pickle.dump(sc,open(\"ScalerFor50Startups.scale\",'wb'))\n",
    "#Deploy PCA object\n",
    "pickle.dump(principalComponentsFinal,open('PCA.pca','wb'))\n",
    "#Deploy Model\n",
    "pickle.dump(knn,open('Model50Startups.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
